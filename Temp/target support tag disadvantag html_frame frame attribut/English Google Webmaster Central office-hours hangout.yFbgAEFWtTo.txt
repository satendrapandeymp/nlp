all right welcome everyone to today's Google Webmaster central office hours hangouts my name is John Mueller I'm a webmaster trends analyst here at Google in Switzerland and part of what we do are these office hours hangouts together with webmasters publishers SEO who wants to join in as always if any of you want to get started with a question feel free to jump on in now let's not if that's okay good hi there my name is Erin I'm from the UK I've run a couple of travel businesses we've just acquired a fairly large website called Travel Guide calm it was presently previously in two different websites travelgate Europe calm and travel by Asia Calm we decided to merge them together starting by traveling Travel Guide calm and since we stood down put in 1 redirects we've seen the traffic dropped by about 80 percent and we checked we've done all the correct redirects we've used the site move tool we think that the problem might be around this domain previously haven't been used about ten years ago as an adult domain and potentially when we've looked at Safe Search it's on quite a lot of Safe Search now Bing have now lifted that safe search the traffic's were covered but I'm just trying to find out how the how we the other do we have submitted a safe search request about 10 days ago yeah those requests sometimes take a bit of time to get processed but that's that's definitely the right place I paint the safe search team about that just before the Hangout as well when I saw you a question so I hope that'll that'll get processed there usually it can take a couple of weeks for us to process these kind of requests so if you just submitted it maybe ten days ago then a couple of the weeks is kind of reasonable and it takes a bit of time for all of these changes to bubble up into the search results as well afterwards so maybe this really was just a matter of time or maybe like this additional nudge from our side helped a little bit but do you think that eighty percent drop is probably correlated to that it's it's hard to say I looked at the the Europe sites that you link there as well and that one didn't seem to be affected by safe search so I don't know if it's not effective anymore because there's no content there obviously now or if it was never affected there if it was never kind of under a safe search then that could definitely have an effect in the sense that when we can tell that people aren't searching with that setting or explicitly looking for this kind of kind of adulty content then that that could have an effect I don't know what what percentage would be reasonable there it probably depends a lot on the website okay yeah that's great thank you very much I think most of it is organic traffic which is why we we're just keen to see that obviously yeah I don't know if like all of that would be from this especially since you now mention that you you actually merge two sites there then that's also something that takes a bit longer for us to actually process if you're just not the second untouched at the moment so travel gauger is still untouched and that hasn't seen anything so the next maybe much time is to merge it once we've got the first one out the way base yeah I wait for it to kind of settle down for us but that's that's always tricky I think in general when you're merging or splitting sites that's something that takes a little bit longer if you can do it step by step that makes it a little bit easier and a little bit easier to figure out like where things went wrong something does go right thank you all right amen I think you had yes thank you very much John I I actually have three questions one is I just posted a message short message in the group maybe two Darren can answer it or somebody else or do John is there I didn't hear I didn't know that there is a way to submit a safe search request to Google if there is would you please pass the link in the chat and maybe maybe I can explore that my second question is and I think you may have in the past rested I just wanted to ask if there isn't any update on this several months ago actually more than more than six months ago we did mpa for all our articles and I was wondering do we need like we see that our MPA pages are not actively crawling I don't know why so do we need a special special sitemap for am a MP pages accelerated mobile pages to rank better that my sec that's my second question and the third question what is the best should I address that third question after distance not before the abbot's before I fade okay yes because that is most important okay yeah so I guess the the link I I have to look up it's in the webmaster Help Center I I think sometimes it's harder to find so usually what I do is I search in the webmaster help forum for one of these threads that occasionally come up and then so I'll post the link there and then I follow that link for crawling EMP pages usually you don't need to do anything so what happens is we recrawl the ANP page when we recrawl the the normal web page when we see the the link rel amp HTML on those pages then we'll recrawl the amp page as well and we'll also recrawl the amp page when a user views a page in the cache so if someone goes to the amp cache then we'll recrawl it after the user kind of views and the cache page so that we have a chance to update the cache that we have there so it's not that they need to be indexed on their own usually third they're not indexed usually the normal web page is zone that's indexed and the amp page is just kind of swapped out for that and we crawl the amp version for two reasons one is to make sure it's really a valid amp page and that it has a canonical back to the web page and the other is for the amp cache so that we can show it in the am cache okay hmm thank you so much and my third question does an average news website which is publishing original new stone have a fair chance to appear in Google top stories or a MP news top stories until about six months ago we are at my website is port news.com port news which is we covered car news I made a comment under your you probably have seen John about December of last year we stopped appearing in top stories but for example I mean you're talking about branding you have to people need to talk about your website and so we are the only web site on the net car from car websites that for example covers subaru news subaru car stories every day no other web site does that but we never appear in top stories even if you search for subaru news we're on the top of search engines what can we do to have a fair chance to appear in Google top stories that's killing our traffic not appearing do please can you take a look at our website ok I I think that's always a bit tricky because the top stories is from our point of view and organic search element which which we treat as something like any other part of the search results that we don't have an explicit kind of like turn on turn off button that we can manually adjust there it's really based on on what we've crawled in index from your website but I I can definitely take a look at your site lead onto the top stories team to look at I know the tops the the people working on the top stories features they've been quite active and are working on various iterations to make it I don't know it possible to just show different kinds of content it's already something that's not tied to Google News for example so this is something where we're trying to figure out what what the right experience there should be and what kind of comment we should show for which kind of queries thank you for listening that's that's something there they're still working on it's it's a fairly new feature so I would certainly expect to see some changes there I know if for your specific case if that would be enough to say like ok it's bright enough to kind of go through the top stories and we are showing a lot more or different kinds of queries we start showing your results I don't know if that would be the case but I do know that that they're working on this and they do take kind of escalations that we send their way thank you seriously so is it okay if is it okay if in the chat room of this message I passed my website and you know so you can see it I think you posted it in one of the questions right yes because I also have a second website which is a health website same situation at least you can send it to them too okay sure thank you so much John I greatly appreciate this like I don't know if they'll be able to change anything but they can take the good that they can take a look if the original originally unique content growth with the team and I have no idea why we're not appearing there okay thank you so much all right let's take a look at what all was submitted and if any questions from your side come up in between feel free to jump on in and probably we'll also have some time for more questions on your side definitely sink in traffic and these few factors like a ranking and backings sorry I didn't quite get that how to change one domain to another domain without losing traffic how to move like from one domain to another we have a Help Center article on that I I will double check on that it's I think it's called like changing your domain name let me just check is in each unit on is required our change of address is the number and you have to set up the redirects and all of that so not just the change of address request I I can pull that out and post it in the chat if I have an a hey NPP's that's an exact duplicate of any other page will it hurt is zero that's kind of the the normal situation that you have one version as the normal web page and the same content as an amp page so that's ideally the way that you would have it set up yeah thanks alright so let's run through some of these questions all right I have a question regarding crawl anomaly report in the new search console I got a lot of very old like 2015-2016 404 error pages reported as crawl anomalies why are they still reported as crawl anomalies and not 404 as the documentation is kind of minimal so it's kind of confusing I guess so first thing I would do there is submit feedback in the new search console I know the search console team is actively watching out for all the feedback in the new new part of search console so if anything is confusing in there always make sure to submit feedback to them so that they're aware that this is confusing and you don't know this means or why why is Google showing you this and not something different so that's kind of the first thing I will do there the other thing that I keep in mind especially with crawl errors is that we crawl or we remember URLs for a very long time and even if they return 404 for a long time then we might still remember them and we try them from time to time so it can certainly happen that a URL that used to exist on your web site a long time ago is still occasionally recrawled and that's not a bad thing so from our point of view we show that in search console specifically as a crawl error or as a crawl anomaly or whatever it happens to be and just so that you're aware of this that we try this URL it didn't work and if that's okay with you that's that's fine if you wanted to actually have content there then you might need to double-check your server configuration and make sure that it's actually has content and it's returning a 200 code instead so that's kind of what what's tied in with there so in general I wouldn't worry too much if you see old crawl errors in search console like that all right does Google unofficially support href Lang attributes in anchor tags so for example in a tag with an href and href Lang link attached to it and no well we as far as I know we we don't officially or unofficially support a trifling links in anchor tags if you want to use href Lang links then I'd really recommend just using them the way that we have them documented in the head of a page and HTTP header or in a sitemap file usually setting up a try flying is complicated enough with that basic set up especially if you have a lot of different language pages or a lot of pages that you use with HF Lang so I be really I'm kind of worried if if the team came to us is it how about we also support HOF laying in this completely different place on a webpage because that just adds so much more complexity and makes it so much harder for most webmasters to actually get rid right so I really recommend using it in the kind of traditional in the normal place we recently moved our website oh this is the one we talked about before we're facing a problem with declining click-through rate caused by the video snippet in the search results we consulted with you in previous hangout session and you recommend it to block Googlebot from crawling the video file which seemed to work at first because we lost the video snippet gaining their click-through rate back but then it reappeared a few days later watch what could be happening here is just like a Google test or what so my guess I don't know which which cited this is at the moment but my my guess is either we saw it the video file from another location or its embedded in a slightly different way or it's it's a matter of things kind of just settling down in the final state in the sense that maybe some said data centers have the updated content with the non video snippet and others still have the older content with the video snippet they were showing that so that might be happening there too and that sometimes it just takes a little bit longer to settle down the other thing is you disallowed the video file with a dollar sign at the end of the URL according to to the comment that you have there that means if the video is embedded in a way that has a URL parameter or anything attached to it it might be that we still try to crawl that video and that we'd be able to crawl it because the disallow and the robots.txt file like that is very specific in that anything that ends with lowercase mp4 would would be blocked from crawling so any other variation might still be probable and depending on how that's embedded on the page that might still be something that that's being picked up on I don't know if you'd be able to see that directly in the video snippet but you should be able to double-check that in your server logs if you have access to that to really confirm like are we crawling any other video files and showing that instead then here's it here we go I'm creating an AJAX based data visualization tool names are loaded with infinite scrolling SVG and text elements change in response to clicking on names in addition the URL is sometimes modified with a hash fragment to enable the back button functionality and to assist crawlers what's the best way to assist Google BOTS crawler to traverse these hash fragment pages or include them in a sitemap will it be published punished for content so I think first of all we generally don't crawl URLs with just the hash fragment so if you just have the hash sign and then some text afterwards usually we drop that and only crawl the version without the fragment there extremely few cases where we do recognize that this is something that's critical to a page and then we try to pick that up and actually follow that but for the largest part you can assume that we were not going to crawl or index any hash fragment URLs so what I'd recommend doing there is using the html5 history API instead with that API you can change the normal part of the URL and use that for navigation within a JavaScript app for example so that that might be an option there to make it a little bit easier to crawl through through a website like that the other thing where I'm not really sure how you're going to be handling this is with regards to the links on the page the infinite scrolling part the text elements you have on a page SVG's that you might use with text in them as well or with links in them as well all of these things make it a lot harder for us actually crawl and index a website so in particular if we have to use rendering to view all of this content that means it takes a little bit longer for us to kind of pull in all of this content and be able to show it in the search results and additionally if you require rendering so that we can crawl through the rest of your website all of those crawling steps each individually take a little bit longer as well and finally depending on the way that you're setting up infinite scrolling and SVG's and text elements it might be that we don't even recognize that there's content here that we need to index properly so my recommendation here would be to kind of be cautious with regards to this setup and to kind of get advice from other people with regards to how you can set it up in a way that works well for users and that works well for search that could be to have something like pagination on the bottom rather than just infinite scrolling you can also combine the two of course it could be to make sure that you have some elements that are within static HTML on these pages as well so that when you open a page for the first time you see kind of a pre-rendered version right away rather than that the client has to process JavaScript and do all of this fancy stuff to just show the primary content so I wouldn't say it's impossible to set up a web app to be crawled and indexed like this but it's definitely the the harder level compared to something that's more static HTML Audient and there's nothing wrong with like taking the hard approach to a problem like this I think it's something you you would learn a lot from and it's something that's extremely valuable because lots and lots of sites are using these JavaScript frameworks nowadays and they also need help with regards to search so having experience on a JavaScript based website with regards to search I think it's something that's really useful to have quick question regarding titles and HTML improvements I asked a couple of time ago in the JavaScript sites Google Groups but I didn't get any help let's see problem how Google identifies titles for JavaScript sites or if it's our angular implementation at Google warns us about pages with duplicate title tags but the pages have different titles in our back-end and front-end and the problem is that Google seems to get the correct title but in a different language so for page a and English it takes a title for page a in German for example and I think Google is penalizing us for duplicate content so I think that last part is definitely not happening Google is definitely not indexing a site for duplicate content with regards to things like titles I think the main issue I would watch out for here is if we're switching titles between individual URLs that sounds like something on your back end is not working the way that it should be working in the sense that we should always be able to fetch fetch a page and render a page and get exactly the same title every time it should not be the case that depending on like how pages are crawled and rendered that certainly in pages title would be in a different language so in particular we don't use cookies for different languages we don't use cookies when crawling and rendering so that's something where you need to have it set up in a way that we can crawl that specific URL when we look at that page we get a specific title in the in that language and not that there's any kind of crosstalk happening there usually what what can happen when the when the content itself is very similar we might fold them into one where we say this one this the set of URLs has exactly the same content as others and then we have like one version usually that doesn't happen for individual languages but more within like the same language so if you have a German page for Austria and a German page for Germany and the content is exactly the same then one might say well this is a German page so in a case like that you would have enter the same content on two pages it wouldn't be the case that we would swap the content so if you're seeing that works and it's working especially across different languages from night one of you that's a really strong sign that this is on your side on your back end so I kind of try to dig into that first we we've seen a lot of emphasis being put on reviews and star ratings including Google surveys how much our search results affected by these on-site surveys and in turn the star ratings for example if I run a survey on my site and we see mostly lower ratings will this hurt my search rankings or prevent me from climbing higher in the search results or does this only matter for local searches and or should brands focus on surveys and reviews so I think there's a few aspects there that we can take a quick look at on the one hand we don't use the content that we see in surveys as as a ranking factor so if you have a survey on your site and currently the service is like two stars we're not going to rank your site lower because you have like something that says two stars on there because we also don't know what these two stars mean it might be that one star is like the best and fewer star at more stars is something different it's like it's really hard to tell we don't know offhand there but in general we wouldn't rank them differently in the organic search results based on the star rankings it might be different with local search where you might have your Google my business listing and you have reviews attached to that Google my business listing but that's completely separate from the normal kind of organic search results that we have there so those are kind of the first things there if you do want to have reviews or kind of star ratings on your pages that's something you can add with Rich Snippets or with the schema.org markup that you can put on your pages we we have a lot of information in our developer site on how to set up these review reviews on your pages with what the requirements are there for those reviews and there's also a code lab for kind of like setting this up on a set of HTML pages by yourself and these are things that we will just show in the search results so if we decide to show your review rankings in the search results we will just kind of show that as a part of the snippet it wouldn't be the case that we will drink those pages higher or lower because of the content there so that's those are kind of the options that you have available there and they're different effects and it's not something that every site has to do obviously for some types of content it makes sense to have some reviews on there that users place it really kind of depends on the type of content you have and that also drives whether or not even it's even possible for you to use review snippets so in general we expect that the structure data reflects the primary object that you're talking about on that page and not that you just put structure data on every page of your website and kind of have it set up like that hi John may I ask a question sure so we we are a big Q&A website with verified experts answering questions and for the last two years we are implementing AET strategy you know like to drive Authority Express Authority trust force in us and so on and by some reason since September 2017 every time when Google is doing core update we are seeing it in traffic a significant and we're not doing anything wrong we think so I was wondering if I may ask you to maybe take a look and maybe tell us what is the main thing we have to fix maybe if anything sure you can post your URL in the at maybe but it's it's really hard to look at these sites like in a live situation because you you really need to dig into the details to see if there's anything that we could even say that is happening there but you're welcome to post it in the chat there in general a lot of the kind of more regular updates that we do they're not specific to any particular factor on your website it's more a matter of where we think your website would normally fit in with regards to search results and sometimes that goes up for a website when we think well we probably didn't treat it as well as we could and other times it goes down a little bit where we say well maybe other results are actually more relevant for in these kinds of queries at the moment according to our systems so the these kind of changes are not not tied so much to like a specific page on your website or a specific technical setup that you have on your website it's more that we're looking at the bigger picture and trying to figure out what is actually relevant or more relevant for users and these things can change a bit over time that makes sense we were just wondering you know if there is a like a really issue and we are just blind and don't see it you know yeah I'm happy to take a look so feel free to post the URL in the chat here I don't know if I'd have something that I can pass on back to you and saying you need to fix this so you need to change this but happy to take a look maybe there is how are they saying thank you all right we have competitors with deep pockets who've done everything in their power to hurt or discredit us one has even linked us hundreds of thousands of times to Russian porn sites generally directed at our home page and certain tag pages I don't understand this allows and there are even warnings beforehand that concerned me have and others put them in for me in the past how important our disavows and how long does it take to see positive effects after putting them in and shall we I keep doing this over and over so in general these are the type of things that we recognize as well we've seen like tons of the these kind of spammy links kind of come and go and it's something that our algorithms try to just ignore so instead of saying well this is a problem and this website did this on purpose and we will kind of need to demote them to take care of this it's something that we find works better when our algorithms can just like recognize these issues and ignore them completely on our side what I would just do however is if you notice this type of thing is happening and it worries you and you're not sure like is Google really recognizing this or not then that's the situation where I might go and just put them all into a disavow file ideally by domain that way you don't have to do with that much work and just submit that and that way you're sure that Google will not take those into account in general because we already ignore most of these probably you won't see a big change up or down with a disavow file like this but at least you're sure that Google really doesn't take these into account at all so that's kind of where I would focus there where if you're really worried about this problem you're like I don't know if Google is treating my site properly or not then go ahead and put them in disavow if this is something that you've just seen and you think oh it's kind of weird then I would just skip over that and just say wow it's not no big deal I mean I mean one of them linked 80 close to eighty four thousand times I mean they're like thousands and thousands of these I mean they're paying they're paying people to do this all day long link 84 thousand times to our home page which is more than we've been linked by a MSN when we get linked by MSN a lot so it's one of those things when you look at links to your site you know it's it's legitimate places and then it's something with a rather or ethic named ru and you go WOW what's going on here yeah I mean the easy part there is that you you can just put that one domain in the file and then it's like all of these 80,000 links are just gone so that makes it a little bit easier you don't have to kind of keep keep following up with that but in general we do take care of these so these are things that we've seen day in and day out for for many and we we basically just ignore them but again if you're ever worried about this if you're ever like in the situation like I'm losing sleep and I don't know how Google is treating my site then I would just put them in a disavow file you don't have any downside to putting those kind of links in it is about and and and some of the sites as I go through a link by link by link it's not that they're offensive content but it's completely like unrelated like horse farming it's like and I I'm one of them really in the tens of thousands and it's horse farming and I don't know whether at some point that site had a connection to entertainment I doubt it but you know is that something you would disavow awesome because it has nothing to do with what we do no I I wouldn't worry about that I mean what would happen in the worst case is that suddenly for horse farming terms your site yeah pretty sure do you think interesting no that's good to know and and also I asked so we do you know we have lots of old content that we did redirects and some of it we just actually decided let's remove its thin content that's nothing usually when I do the removal of URLs within 24 hours it says removed and then maybe for 48 hours it says expired it's been stuck at pending now for four days which is yeah so I I don't know if this is in your situation if this happened there but in general there there two ways to submit URL removals one is within your search console account where it's like clearly tied to your account and we have understanding that kind of you're the owner that you you've got to make these decisions and those are the ones that we generally process within less than a day and you can also submit them with with your normal Google account in general or with anyone's Google account and those are ones that generally take a little bit longer because we want to make sure that this URL is actually really gone thank you we do it through webmaster tools through the console I mean yeah yeah just for some reason this this past week is it an individual one or is it a whole dad that's about 125 that if they just saw you sitting there okay that sounds kind of weird that I'll take a look at that yeah thanks thank you oh and one last thing if I may ask sure it's sort of related to the disavow you know we clearly have people who were an independent company we go against honestly conglomerates that are in the billions worth millions they have a lot at stake they use the feedback we know this we have moles everywhere we know they use the feedback section we know they use their interns we to denigrate us does that have any effect on ranking and how one is trusted or rated in any way no no that's something that goes to the the search team to the search quality team to the user experience people and they take this feedback in a way to to kind of better understand where what people's thoughts are and what kind of content they would like to see in individual situations so that's something that usually is is more of a longer process and more of some things like oh we've seen people complain about I don't know amp pages because they don't like them whether they don't like the logo or something and this is like we've seen lots of people complain about this over time so maybe we should change something slightly there but on the basis of individual sites that's not something that we would use for so it's really a matter of like this is a general trend and they're not focusing on one specific site but rather like this whole different area that we're kind of getting wrong and searched and we get feedback from all kinds of people on that general area and because of that we we should figure out I don't know some approach that we can do to make it easier to show more relevant results to to the bigger group of people all right so more questions that were submitted to questions about impressions in search console if a website is on page two and the person searching for a particular keyword phrase is not visiting page two would it still be counted as an impression and no it's really only counted as an impression when the user would actually see that in the current search results page and I think it goes on says like there's like some weird impressions that probably look a bit weird I guess in search console I think in general depending on the type of website that you have you you will sometimes see these weird kind of edge cases where someone is searching on page ten of the search results for this particular query and that just happens sometimes so that's not something I would say is a problem with the data we really only track these when we actually see them in the search results happening maybe people just search in unique ways sometimes you're really desperate to get that information on a specific topic you can't find the right term to get exactly what you're looking for in the search results so you just flick through a couple of pages it happens and the second one is when I check the Adwords Keyword planner I can see that a certain keyword is searched for 2,000 times a month but my impressions only show 300 per month and on page one why is there a big difference so first off I don't know how the Adwords Keyword planner calculates these numbers so that's really hard to say it might be that it's bucketing individual numbers there it might be that it's looking at a global count and your site is not ranking number one like everywhere for those terms all of these things can kind of come together and in general depending on the way that you look at impression is the way that you track them for example if you also look at Google Analytics or other analytics tools you'll always see some some general difference across these different ways of tracking information and especially if you're looking at something that's relatively in low numbers where you're talking about hundreds or low thousands per month even small changes on a day to day basis they can skew this number quite significantly so that's also something kind of worth keeping in mind in that some amount of fluctuation is completely normal there and even when you're looking at trends it's kind of tricky to look at something which has a couple hundred per month when it goes up 10 percent or down 10 percent those are changes that are in absolute counts like very few so those are kind of things I would watch out for with regards to kind of checking across different tools and different different ways of measuring things and that doesn't mean that any of these tools are less useful than others it's just you have to understand what they're kind of measuring and maybe look at the bigger picture and look at relative differences as well where you see this tool says 2004 this term and 200,000 for another term that's obviously a pretty big difference so that that's something that might be more useful to focus on instead continuing the impressions question if a search results is in the tenth position and the user had not scrolled down to see that result would that still be counted yes that would still be counted so if it's on the current search results page then that's that's counted we have a Help Center page on clicks impressions and position for search console specifically that goes through a lot of these edge cases also kind of the the situations with regards to what if there are images on top or what if there's a carousel on top of the search results page how does that actually get counted and okay a question on multilingual SEO without duplicate content issues in general if you're doing content in different languages it's not a matter of duplicate content so if you translate your content from one language to another and you publish that under a different URL on your website we don't see that as duplicate content it's essentially the same information that you're providing there but it's completely different content it's a different language it's a different target audience essentially so we would treat that as as unique content so in that regard if you feel that you have users or you might have users that would be interested in seeing your content in one particular language then I would definitely go ahead and try to get that set up with with localized version of your content what's a rink what's the difference in ranking for an old website a new page and a new page on a new domain let's see with the suggestions it means that we shouldn't go with a CTC TLD but rather create separate folder and target individual countries or also MDOT are not in general these are i i'd say kind of different situations if you have an existing website and you add a new page to an existing website and for a large part we understand that this website already has a lot of context on the internet and it makes it it was a lot easier for us to understand those new pages that you're placing on an existing website whereas if you start over with a completely new website then obviously we need to understand that website first so that's something that always kind of plays in there that doesn't mean that the end effect is better or worse it just means that in the beginning we we have a lot more context so we can kind of use that context to understand those new pages a little bit better with regards to ccTLDs or sub directories or subdomains when you're going international from my point of view this is something that you can take into account if you want but it's probably a really tiny effect in the long run so in general when it comes to things like CC Tobs or using a subdomain or using subdirectories that's something where I would focus more on what your technical capabilities are what you can do on your side can you put completely localized content within a subdirectory on your website or not in many cases that something is really obviously yes or no so you can do it or not if you can't do it then obviously you go with like an approach that you can do a little bit easier sometimes there are also situations where you need to use a CC OTA CC Tod for legal reasons and obviously in cases like that if you need to use it and you need to use it right and from our point of view we think that in the long run any kind of internationalization setup that you have we should be able to pick that up and just go with that naturally with regards to mobile first indexing and MDOT subdomains that's something that from our point of view is completely separate in the sense that at the moment an MDOT content is something that's attached to the desktop page we understand that this is the desktop URL and this is the mobile URL it can be on the same domain it can be on a different sub domain it can be on a different domain completely even and that's something that we just use for recognizing where the mobile content is and swapping out the URLs so that doesn't have any effect at all with regards to mobile first indexing later on when we shift to the MDOT versions essentially what happens there is that we just shift the the indexing to that other version it's not the case that you would see any kind of ranking change that would be similar to like moving to a different website there so with that said I will primarily focus on what you need to do on your website we for mobile indexing we recommend using responsive web design if that's something that you can do so I try to avoid setting up new MDOT sites it just makes everything so much more complicated but if you currently have an MDOT site it is the way it is and we should be able to just deal with that seems like the new search console is incorrectly reporting lagging pages and host smart as noindex I don't quite understand what you mean in that regard maybe you have some more information somewhere or what might make sense is maybe link to help forum thread that you have with with that more information I can double-check there after the Hangout what's the best practice to handle localization of domains suffixes my question has to do with internationalization we have a dot-com domain our goal is to break into the EMEA markets and we'd like to obtain domain suffixes relevant to the countries we will be targeting however we don't want to manage multiple websites so we would like to have the same or very similar content on all of these domains how will this affect our web rankings I think it's kind of tricky and if you have exactly the same content and you're just saying this is localized for different markets because it's not really localized so what would happen in in general here if you have the same content on your comm as you have on your dot I don't know de or dot F our website is we would look at that and recognize that it's the same content and we would pick one of these URLs and treat it as canonical and that's the one we will focus on for search so probably that would be the one de you currently have if you're just copying the content from there so that means you would have these different country code top-level domains but in search we will just show the dot-com version because we're trying to make you do your favor and say well probably you mean just index your main version of your website so we'll try to do that what you could do to change that a little bit if you wanted to is to make sure that you actually have localized content for those individual country country markets so that we can clearly recognize that actually there is something unique here that we should index separately from a practical point of view with the first set up if you just copy the content the users can of course go to those URLs directly you can use those URLs directly for things like ads or links or anything else that you have kind of happening with your website and that be perfectly fine that might be good enough for you we still in Dixit calm but you have I need advertisement running for fr because you're doing some local promotion or whatever you're doing there if you do want to use the country code top-level domains again you'd need to have the unique content there so that we actually recognize that and what also helps us a little bit is to have the HOF Lane links between the different language versions or the different country versions so that we understand which version we should show in which individual country for a large part we already understand that based on the domain ending of course by the top-level domain so if you have de that kind of tells us pretty clearly that this is the one that you want to have shown in Germany in general though what I'd recommend doing there is if you're really just starting into this for the first time I would recommend getting help from from some expert who's done this a few times because there are some things that you can run into which make things a little bit more complicated than they need to be especially if you can do that kind of ahead of time rather than responding to something actually breaking and some of these consultants and experts can also give you a bit of advice about whether or not it actually makes sense to do that in your situation because a lot of times it's perfectly fine to have one large global website and to just use that internationally it doesn't prevent your website from showing up if you have a dot-com for users in France or in Germany they can still find your website just fine so all of these things are topics that are kind of complicated they depend on a lot of individual situations and specifically around your website the capabilities that you have with regards to localizing content or not so I try to get some help there before you just run off and kind of buy all these different top-level domains list and set them up we have a portal which has English and French versions of the same content on the same URL separated by query parameter called set language equals fr can we assume that all our English and French versions of your URLs are naturally indexed probably probably so if we see links to these individual language URLs so in this case they wouldn't be the same URL but they would have the the query parameter in the end with language equal French or in English if we see links to those pages we will probably crawl and try to index those pages separately and will be perfectly fine so what you can do is double check and search do a site query for your website maybe use in URL and include set language or set language equals fr depending on how you have that set up and see what you actually have indexed for from your website already and my guess is if you set this up in a way that you have links to those language versions that will probably pick that up properly and you don't have to do anything special there all right let's see any any more questions from your side that's okay any chat but it's about the 301 redirects we've put in place on the original domain obviously back to main the Europe travel go Europe domain has now dropped off Google in the index and as and when we start we ranking Peggy when safe search is listed well that the waiting that was behind that domain passed through to the to the new domain still yeah that period loss is there a time where that drops off so usually I'd recommend just keeping those redirects in place as long as you can definitely at least a year so that we can actually pick that up yeah that's one so I I mean if these are your domains I would just continue to keep that and keep that redirect set up so that keeps passing everything on yeah but in general once we we've been able to kind of understand the content of your new domain and understand that it's the same as the old one then that should pretty much be be similar or the same with regards to ranking it's always there are always some possible fluctuations that happen when you do a site move but in general it should kind of settle down about it to say yeah I mean we've noticed that most most and some keywords are still in the same place if you've got Safe Search off others which was some of our most popular pages it disappeared to page 11 or 12 but I'm sure that will come back I've only moved a month ago six weeks ago probably but obviously the safe search thing has really affected that traffic yeah I take a look when when things settle down there it's it's always tricky to check the rankings when when you have such a change with regards to save search on and off okay thanks sure all right so looks like the URLs are in the track here so I can copy that out and keep a copy of that so that I can double-check those URLs all right that's the question John quick question race all right first of all I really thank you very much for introducing our URLs to the top stories team and that time frame link if let's say they say oh these are some great websites good stories were going to include realistically when can really expect to change because this is so important for us our entire business is the state because of this we're in the news business but we never appear in the top stories despite publishing seven ten original stories every day by professionals so when can we expect any change if at all I I can't make any promises there so that's something that really kind of depends on where they see the problems for the most part these these kind of issues are more kind of algorithmic changes that we have to make and that's something that depends a lot on when they're able to obtain these algorithms and one less good yes that includes a lot of testing time as well so it's really really hard to say okay and one last question please let's say there is a problem on our end this is one thing that I would like to give a feedback for google webmaster tools I know you have changed it a lot it gives us a lot of feedback but let's say the problem is on our and we're not able to see is there a way you can at least message me something to say Arman this is the problem look you know the caching issue here or something so we can fix it please yeah thank you so much John I appreciate it that sometimes we sometimes do as well thank you so much from the indexing of no ranking teams like this this guy is making some some simple mistake and they're probably not recognizing it then give them a note in search console uh-huh thank you so much sure all right so thank you all for joining it's been great having you here there's lots of good feedback lots of good questions and I hope to see you all again and one of the future hangouts thank you very much you have a great one bye bye everybody		